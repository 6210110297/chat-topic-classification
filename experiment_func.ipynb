{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA COLLECTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pythainlp.tokenize import THAI2FIT_TOKENIZER\n",
    "\n",
    "# message converter\n",
    "from project_module.message_data_converter import MessageDataConverter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('./raw_data/wimon_message_1.json')\n",
    "json_obj = json.load(json_file)\n",
    "message_list = []\n",
    "\n",
    "for message in json_obj['messages']:\n",
    "    try:\n",
    "        message_content = message['content'].encode('latin_1').decode('utf-8')\n",
    "        message_list.append(message_content)\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter non contain thai character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding constant values\n",
    "text_bytes_code = '‡∏Å'.encode('utf-8')\n",
    "print(text_bytes_code)\n",
    "print(len(text_bytes_code))\n",
    "\n",
    "text_int_code = int.from_bytes(text_bytes_code, 'big')\n",
    "print(text_int_code)\n",
    "\n",
    "text_int_code += 62\n",
    "\n",
    "text_bytes_code_last = text_int_code.to_bytes(len(text_bytes_code), 'big')\n",
    "print(text_bytes_code_last)\n",
    "text_last = text_bytes_code_last.decode('utf-8')\n",
    "\n",
    "print(text_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use constanst values to create map\n",
    "thai_characters_offset = 14727297\n",
    "thai_characters_bytes_len = 3\n",
    "thai_characters = [ (index.to_bytes(thai_characters_bytes_len, 'big')).decode('utf-8') for index in range(thai_characters_offset, thai_characters_offset + 63) ]\n",
    "print(thai_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtter messages\n",
    "filter_func = lambda s: any(x in s for x in thai_characters)\n",
    "\n",
    "message_list_filtered = [line for line in message_list if filter_func(line)]\n",
    "\n",
    "print(message_list_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORT TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'message': message_list_filtered})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('message_csv.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_converter = MessageDataConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_converter.import_json(path='./raw_data/wimon_message_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_converter.get_message_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_converter.export_csv(path='./data/message_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_data_converter.merge_csv(csv1_path='./data/message_1.csv', csv2_path= './data/message_2.csv', des_path='./data/message_12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many JSON in folder to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init converter\n",
    "message_data_converter = MessageDataConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mypath = './raw_data/'\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(onlyfiles)\n",
    "# for f in onlyfiles:\n",
    "#     file_name = f.split('.')[0]\n",
    "#     message_data_converter.import_json(path = f'./raw_data/{f}')\n",
    "#     message_data_converter.export_csv(path = f'./data/{file_name}.csv')\n",
    "#     message_data_converter.clear_message_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed many file convert func. in module\n",
    "message_data_converter.convert_many(json_path= './raw_data/', csv_path= './data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged Multiple CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data_converter.merge_many_csv(src_path='./test_data/', des_path='./data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Words in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/message_temp.csv\")\n",
    "data = data[['message', 'category']]\n",
    "\n",
    "word_list = set()\n",
    "for text in data['message']:\n",
    "    \n",
    "    text = text.lower().replace('\\n', ' ').replace('\\r', '').strip()\n",
    "    text = re.findall(r\"[\\u0E00-\\u0E7Fa-zA-Z']+\", text)\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    word_tokens = THAI2FIT_TOKENIZER.word_tokenize(text)\n",
    "    filtered_sentence = set([w for w in word_tokens])\n",
    "\n",
    "    word_list.update(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Empty Data On Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/_csv/3hnum3mum_message_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    #filter na\n",
    "    data = data.dropna()\n",
    "    # filter common chat\n",
    "    # data = data.drop(data.index[ data['category'] == 'C' ])\n",
    "    # sort data by category\n",
    "    data = data.sort_values(by=['category'])\n",
    "\n",
    "    data = data.reset_index()\n",
    "    data = data[['message', 'category']]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('exenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8e4a78b937a3ac7834a977c99d86d4585a7e3d43b43b35443d49476bbdeb382"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
